{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5e32c87-6887-484f-8da5-07cffe8e11f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from numpy.random import choice\n",
    "import numpy as np\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from datetime import datetime\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.cm import ScalarMappable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95d406fb-0d47-4c90-a0f5-fe9e30c98257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/553303/how-to-generate-a-random-date-between-two-other-dates\n",
    "def str_time_prop(start, end, time_format, prop):\n",
    "    \"\"\"Get a time at a proportion of a range of two formatted times.\n",
    "\n",
    "    start and end should be strings specifying times formatted in the\n",
    "    given format (strftime-style), giving an interval [start, end].\n",
    "    prop specifies how a proportion of the interval to be taken after\n",
    "    start.  The returned time will be in the specified format.\n",
    "    \"\"\"\n",
    "\n",
    "    stime = time.mktime(time.strptime(start, time_format))\n",
    "    etime = time.mktime(time.strptime(end, time_format))\n",
    "\n",
    "    ptime = stime + prop * (etime - stime)\n",
    "\n",
    "    return datetime.fromtimestamp(ptime)\n",
    "\n",
    "\n",
    "def random_date(start, end, prop):\n",
    "    return str_time_prop(start, end, '%d/%m/%Y %H:%M', prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24ddce94-0063-4b06-9d8b-d13664e67d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normal_indexes(sample_size, example_size, spread=6):\n",
    "    mu = example_size/2\n",
    "    sigma = example_size/spread\n",
    "    return np.clip([int(i) for i in np.random.normal(mu, sigma, sample_size)], 0, example_size-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed88fa-b8bd-4cfc-abcd-a7127019d422",
   "metadata": {},
   "source": [
    "# Warning!\n",
    "- #### If you run the below cells the data set will be recreated and replaced\n",
    "- #### To run the analysis go to the analysis section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "515c42df-96a4-4e92-9776-6c6c9434ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = int(1e5)\n",
    "columns_names = [\n",
    "    \"Data da Venda\",\n",
    "    \"Região\",\n",
    "    \"Vendedor\",\n",
    "    \"Produto\",\n",
    "    \"Categoria do Produto\",\n",
    "    \"Valor do Produto\",\n",
    "    \"Quantidade Vendida\",\n",
    "    \"Forma de Pagamento\",\n",
    "    \"Status do Pedido\",\n",
    "    \"Cliente_ID\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a1b25cb-3092-4bbf-a57b-fcdd0d1b3fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regioes distribuition is based on population %\n",
    "regioes = [\"Sul\", \"Sudeste\", \"Centro-Oeste\", \"Nordeste\", \"Norte\"]\n",
    "regioes_dist = [0.15, 0.42, 0.08, 0.27, 0.08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34d18afc-2c51-4eff-afcc-fe6f9904a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vendedores = [\"Helena\",\"Cecília\",\"Maitê\",\"Laura\",\"Alice\",\"Miguel\",\"Artur\",\"Davi\",\"Antônio\",\"Samuel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7510efb-d122-432e-a541-032ac0892938",
   "metadata": {},
   "outputs": [],
   "source": [
    "produtos = [\n",
    "    #Eletrodomésticos\n",
    "    {\"Produto\": \"Geladeira Brastemp 375L\", \"Categoria do Produto\": \"Eletrodomésticos\", \"Valor\": 3850.00},\n",
    "    {\"Produto\": \"Micro-ondas Electrolux\", \"Categoria do Produto\": \"Eletrodomésticos\", \"Valor\": 620.00},\n",
    "    {\"Produto\": \"Fogão Consul 4 bocas\", \"Categoria do Produto\": \"Eletrodomésticos\", \"Valor\": 1150.00},\n",
    "    {\"Produto\": \"Máquina de Lavar 11kg\", \"Categoria do Produto\": \"Eletrodomésticos\", \"Valor\": 2300.00},\n",
    "    \n",
    "    # Eletrônicos\n",
    "    {\"Produto\": \"Câmera Canon EOS Rebel\", \"Categoria do Produto\": \"Eletrônicos\", \"Valor\": 3200.00},\n",
    "    {\"Produto\": \"Smart TV Samsung 50\\\"\", \"Categoria do Produto\": \"Eletrônicos\", \"Valor\": 2900.00},\n",
    "    {\"Produto\": \"Console PlayStation 5\", \"Categoria do Produto\": \"Eletrônicos\", \"Valor\": 4499.00},\n",
    "    {\"Produto\": \"Drone DJI Mini 2\", \"Categoria do Produto\": \"Eletrônicos\", \"Valor\": 3499.00},\n",
    "    \n",
    "    # Esportes\n",
    "    {\"Produto\": \"Esteira Elétrica Movement\", \"Categoria do Produto\": \"Esportes\", \"Valor\": 5990.00},\n",
    "    {\"Produto\": \"Patins Rollerblade Zetrablade\", \"Categoria do Produto\": \"Esportes\", \"Valor\": 899.00},\n",
    "    {\"Produto\": \"Bola de Futebol Nike Campo\", \"Categoria do Produto\": \"Esportes\", \"Valor\": 230.00},\n",
    "    {\"Produto\": \"Bicicleta Caloi 100\", \"Categoria do Produto\": \"Esportes\", \"Valor\": 2100.00},\n",
    "\n",
    "    # Telefonia\n",
    "    {\"Produto\": \"Smartphone iPhone 14\", \"Categoria do Produto\": \"Telefonia\", \"Valor\": 7499.00},\n",
    "    {\"Produto\": \"Smartphone Motorola Edge 40\", \"Categoria do Produto\": \"Telefonia\", \"Valor\": 3599.00},\n",
    "    {\"Produto\": \"Fone Bluetooth Samsung Buds 2\", \"Categoria do Produto\": \"Telefonia\", \"Valor\": 699.00},\n",
    "    {\"Produto\": \"Smartphone Samsung A34\", \"Categoria do Produto\": \"Telefonia\", \"Valor\": 1799.00},\n",
    "\n",
    "    # Informática\n",
    "    {\"Produto\": \"SSD Kingston NV2 1TB\", \"Categoria do Produto\": \"Informática\", \"Valor\": 480.00},\n",
    "    {\"Produto\": \"Placa de Vídeo Nvidia RTX 4060\", \"Categoria do Produto\": \"Informática\", \"Valor\": 2399.00},\n",
    "    {\"Produto\": \"Notebook Dell Inspiron\", \"Categoria do Produto\": \"Informática\", \"Valor\": 4500.00},\n",
    "    {\"Produto\": \"Monitor LG 24\\\"\", \"Categoria do Produto\": \"Informática\", \"Valor\": 1200.00},\n",
    "\n",
    "    # Áudio\n",
    "    {\"Produto\": \"Soundbar Samsung HW-T450\", \"Categoria do Produto\": \"Áudio\", \"Valor\": 999.00},\n",
    "    {\"Produto\": \"Headset Gamer HyperX Cloud II\", \"Categoria do Produto\": \"Áudio\", \"Valor\": 520.00},\n",
    "    {\"Produto\": \"Fone de Ouvido JBL\", \"Categoria do Produto\": \"Áudio\", \"Valor\": 350.00},\n",
    "    {\"Produto\": \"Caixa de Som JBL Go 3\", \"Categoria do Produto\": \"Áudio\", \"Valor\": 230.00},\n",
    "\n",
    "    # Eletroportáteis\n",
    "    {\"Produto\": \"Cafeteira Nespresso Essenza Mini\", \"Categoria do Produto\": \"Eletroportáteis\", \"Valor\": 520.00},\n",
    "    {\"Produto\": \"Air Fryer Mondial 4L\", \"Categoria do Produto\": \"Eletroportáteis\", \"Valor\": 430.00},\n",
    "    {\"Produto\": \"Ventilador Mondial 40cm\", \"Categoria do Produto\": \"Eletroportáteis\", \"Valor\": 200.00},\n",
    "    {\"Produto\": \"Aspirador de Pó Philco\", \"Categoria do Produto\": \"Eletroportáteis\", \"Valor\": 420.00},\n",
    "\n",
    "    # Acessórios\n",
    "    {\"Produto\": \"Carregador Portátil Anker 10000mAh\", \"Categoria do Produto\": \"Acessórios\", \"Valor\": 180.00},\n",
    "    {\"Produto\": \"Óculos de Sol Ray-Ban Wayfarer\", \"Categoria do Produto\": \"Acessórios\", \"Valor\": 620.00},\n",
    "    {\"Produto\": \"Relógio Smartwatch Xiaomi\", \"Categoria do Produto\": \"Acessórios\", \"Valor\": 480.00},\n",
    "    {\"Produto\": \"Mochila Lenovo para notebook\", \"Categoria do Produto\": \"Acessórios\", \"Valor\": 150.00},\n",
    "\n",
    "    # Impressoras\n",
    "    {\"Produto\": \"Impressora Epson EcoTank L3250\", \"Categoria do Produto\": \"Impressoras\", \"Valor\": 1249.00},\n",
    "    {\"Produto\": \"Impressora HP DeskJet\", \"Categoria do Produto\": \"Impressoras\", \"Valor\": 480.00},\n",
    "\n",
    "    # Vestuário\n",
    "    {\"Produto\": \"Jaqueta Corta Vento Adidas\", \"Categoria do Produto\": \"Vestuário\", \"Valor\": 450.00},\n",
    "    {\"Produto\": \"Calça Legging Nike Pro\", \"Categoria do Produto\": \"Vestuário\", \"Valor\": 280.00},\n",
    "    {\"Produto\": \"Boné New Era Yankees\", \"Categoria do Produto\": \"Vestuário\", \"Valor\": 180.00},\n",
    "    {\"Produto\": \"Tênis Nike Revolution\", \"Categoria do Produto\": \"Vestuário\", \"Valor\": 320.00},\n",
    "\n",
    "    # Periféricos\n",
    "    {\"Produto\": \"Mouse Gamer Razer DeathAdder V2\", \"Categoria do Produto\": \"Periféricos\", \"Valor\": 320.00},\n",
    "    {\"Produto\": \"Teclado Logitech K380 Bluetooth\", \"Categoria do Produto\": \"Periféricos\", \"Valor\": 250.00},\n",
    "    {\"Produto\": \"Mouse Logitech M170\", \"Categoria do Produto\": \"Periféricos\", \"Valor\": 75.00},\n",
    "    {\"Produto\": \"Teclado Mecânico Redragon\", \"Categoria do Produto\": \"Periféricos\", \"Valor\": 250.00},\n",
    "]\n",
    "max_value = max([v['Valor'] for v in produtos])\n",
    "produtos_dist = np.array([100+max_value-p['Valor'] for p in produtos])\n",
    "normalized_produtos_dist = produtos_dist / produtos_dist.sum()\n",
    "\n",
    "#Giving a normal distribuition on products\n",
    "products_indexes = get_normal_indexes(n_rows, len(produtos), spread=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07eca255-b8d9-4e2a-b03d-ade55dcd7571",
   "metadata": {},
   "outputs": [],
   "source": [
    "formas_de_pagamento = [\"Crédito\", \"Débito\", \"Boleto\", \"Pix\", None]\n",
    "formas_de_pagamento_dist = [0.5, 0.1, 0.1, 0.25, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22df640e-7bc2-4b4a-a168-9ea30ba538f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Givin more probability for \"Pago\"\n",
    "status = [\"Pago\", \"Aguardando Pagamento\", \"Em andamento\", \"Em Atraso\", \"Cancelado\"]\n",
    "status_dist =  [0.7, 0.05, 0.1, 0.1, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb199e14-1304-4dc0-af27-0befaad34748",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 1000\n",
    "clientes = [f\"{random.choice(range(100)):04n}\" for i in range(n_clients)]\n",
    "\n",
    "#Giving a normal distribuition on clients\n",
    "clients_indexes = get_normal_indexes(n_rows, len(clientes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d22b441-26c2-4bee-b02b-015d3cbedb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datas inicial e final\n",
    "start = datetime.strptime('1/1/2020 00:00', '%d/%m/%Y %H:%M')\n",
    "end = datetime.strptime('31/12/2024 00:00', '%d/%m/%Y %H:%M')\n",
    "\n",
    "# Gerar lista de n datetimes igualmente espaçados\n",
    "datas = pd.date_range(start=start, end=end, periods=(end-start).days).to_list()\n",
    "\n",
    "# The most recent dates have more probability of get choose, so we see an increase on sales\n",
    "sale_increase = 2\n",
    "data_dist = np.array([(x / (end-start).days)**2 for x in range((end-start).days, sale_increase*(end-start).days, sale_increase-1)])\n",
    "normalized_data_dist = data_dist / data_dist.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83d8dfd7-8349-4618-bf42-a4146c4682d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data columns\n",
    "data_venda_list = choice(a=datas, size=n_rows, p=normalized_data_dist)\n",
    "data_venda_list = [t.strftime('%d/%m/%Y %H:%M') for t in data_venda_list]\n",
    "\n",
    "regiao_list = choice(a=regioes, size=n_rows, p=regioes_dist)\n",
    "\n",
    "vendedores_list = [random.choice(vendedores) for i in range(n_rows)]\n",
    "\n",
    "produtos_list = [p.values() for p in choice(a=produtos,size=n_rows, p=normalized_produtos_dist)]\n",
    "\n",
    "quantidades_list = [random.choice(range(10)) for i in range(n_rows)]\n",
    "\n",
    "formas_de_pagamento_list = choice(a=formas_de_pagamento, size=n_rows, p=formas_de_pagamento_dist)\n",
    "\n",
    "status_do_pedido_list = choice(a=status,size=n_rows, p=status_dist)\n",
    "\n",
    "clientes_list = [clientes[i] for i in clients_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "812d4a6a-b405-4a25-ada6-30da26648672",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [data_venda_list, regiao_list, vendedores_list]+list(map(list, zip(*produtos_list)))+[quantidades_list, formas_de_pagamento_list, status_do_pedido_list, clientes_list]\n",
    "data = list(map(list, zip(*data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820cf2a-e79b-4257-8a8d-686762cd592e",
   "metadata": {},
   "source": [
    "#### Inconsistencies\n",
    "The raw data has the following inconsistencies added on purpose:\n",
    "- The 'quantidades' value may be zero\n",
    "- There are combinations of 'status' and 'formas de pagamento' that may be invalid:\n",
    "    -  \"Pago\" with None\n",
    "    -  \"Cancelado\" or \"Aguardando Pagamento\" with any other then None\n",
    "- Added some None values on columns \"Data da Venda\", \"Região\", \"Vendedor\", \"Produto\" and \"Status do Pedido\"\n",
    "- Added some random duplicates values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a8bdfa8-e1a9-4198-a2a0-16575f03f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    data=data,\n",
    "    columns=columns_names,\n",
    "    index=None,\n",
    ")\n",
    "\n",
    "# Columns where you want to insert None\n",
    "target_columns = [\"Data da Venda\", \"Região\", \"Vendedor\", \"Produto\", \"Status do Pedido\"]\n",
    "\n",
    "# Adding 1% of None values per column\n",
    "n_none_per_column = round(n_rows*0.01)\n",
    "\n",
    "# Add None randomly\n",
    "for col in target_columns:\n",
    "    rows = random.sample(range(df.shape[0]), n_none_per_column)\n",
    "    df.loc[rows, col] = None\n",
    "\n",
    "# Adding 0.5% of duplicates rows\n",
    "n_duplicates = round(n_rows*0.005)\n",
    "# Randomly select rows to duplicate (with replacement if needed)\n",
    "rows_to_duplicate = df.sample(n=n_duplicates, replace=True)\n",
    "\n",
    "# Append duplicated rows\n",
    "df = pd.concat([df, rows_to_duplicate], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e7a047f-6451-4e4c-a061-03f1b52f7f9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_excel(\"raw_data2.xlsx\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f19a95-24f0-494c-aedc-170f96574be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
